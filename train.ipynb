{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2574213a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "type object 'TrainingConfig' has no attribute 'model_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m task \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;66;03m# get the arguments\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m     model_name \u001b[38;5;241m=\u001b[39m \u001b[43mTrainingConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_name\u001b[49m\n\u001b[1;32m     23\u001b[0m     data_size \u001b[38;5;241m=\u001b[39m TrainingConfig\u001b[38;5;241m.\u001b[39mdata_size\n\u001b[1;32m     24\u001b[0m     batch_size \u001b[38;5;241m=\u001b[39m TrainingConfig\u001b[38;5;241m.\u001b[39mbatch_size\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'TrainingConfig' has no attribute 'model_name'"
     ]
    }
   ],
   "source": [
    "from dataset.model_loader import ModelLoader\n",
    "from datasets import load_dataset\n",
    "from bert_routing.train_BERT import ModelTrainer\n",
    "import pickle\n",
    "import argparse\n",
    "import random\n",
    "import os\n",
    "from config import DatasetConfig, MODEL_REGISTRY, TrainingConfig\n",
    "from itertools import product\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "def load_pickle_data(file_path):\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print('Hello World')\n",
    "    task = 'train'\n",
    "    if task == 'train':\n",
    "        # get the arguments\n",
    "        model_name = TrainingConfig.model_name\n",
    "        data_size = TrainingConfig.data_size\n",
    "        batch_size = TrainingConfig.batch_size\n",
    "        context_window = TrainingConfig.context_window\n",
    "        num_epochs = TrainingConfig.num_epochs\n",
    "        strategy = TrainingConfig.strategy\n",
    "\n",
    "        index = 0\n",
    "        # Load test data\n",
    "        test_path = os.path.join(DatasetConfig.DATA_DIR, DatasetConfig.TEST_FILE)\n",
    "        test_data = load_pickle_data(test_path)\n",
    "        test_texts = [sample['text'] for sample in test_data]\n",
    "        test_labels = [[sample['labels'][index]] for sample in test_data]\n",
    "\n",
    "        # Load and shuffle train data\n",
    "        train_path = os.path.join(DatasetConfig.DATA_DIR, DatasetConfig.TRAIN_FILE)\n",
    "        train_data = load_pickle_data(train_path)\n",
    "        random.shuffle(train_data)\n",
    "        train_texts = [sample['text'] for sample in train_data]\n",
    "        train_labels = [[sample['labels'][index]] for sample in train_data]\n",
    "        \n",
    "        if data_size != 'None':\n",
    "            train_texts = train_texts[:int(data_size)]\n",
    "            train_labels = train_labels[:int(data_size)]\n",
    "        num_classes = 2\n",
    "\n",
    "        learning_rates = [1e-5, 1e-6]\n",
    "        layers_to_freeze_options = [2, 4]\n",
    "\n",
    "        grid = product(learning_rates, layers_to_freeze_options)\n",
    "        for lr, layers in grid:\n",
    "            \n",
    "            TrainingConfig.learning_rate = lr\n",
    "            TrainingConfig.layers_to_freeze = layers\n",
    "\n",
    "            trainer = ModelTrainer(model_name=model_name,\n",
    "                num_outputs=len(train_labels[0]),\n",
    "                num_classes=num_classes,\n",
    "                pooling_strategy=strategy, \n",
    "                train_texts=train_texts,\n",
    "                train_labels=train_labels,\n",
    "                test_texts=test_texts,\n",
    "                test_labels=test_labels)\n",
    "\n",
    "            trainer.train(batch_size=batch_size, \n",
    "                context_window=context_window, \n",
    "                num_epochs=num_epochs,)\n",
    "\n",
    "\n",
    "            # Clean up to avoid GPU memory leak\n",
    "            del trainer\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2762cbe7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad1aab48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "salam\n",
      "/data/gpfs/projects/punim2662/LLM_routing/LLM_routing\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print('salam')\n",
    "dir_path = os.getcwd()  # current working directory\n",
    "print(dir_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
